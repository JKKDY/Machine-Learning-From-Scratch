{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internet Resources:\n",
    "\n",
    "[handson-ml/06_decision_trees.ipynb](https://github.com/ageron/handson-ml/blob/master/06_decision_trees.ipynb)  \n",
    "[Sefik Ilkin Serengil - A Step by Step CART Decision Tree Example](https://sefiks.com/2018/08/27/a-step-by-step-cart-decision-tree-example/)  \n",
    "[Google Developers - Tree Classifier from Scratch](https://www.youtube.com/watch?v=LDRbO9a6XPU&t=1s)  \n",
    "[Victor Zhou - A Simple Explanation of Gini Impurity](https://victorzhou.com/blog/gini-impurity/)\n",
    "\n",
    "\n",
    "Literature:  \n",
    "\n",
    "Aurelien geron hands on machine learning page 173"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   petal_length  petal_width  species\n",
       "0           1.4          0.2        0\n",
       "1           1.4          0.2        0\n",
       "2           1.3          0.2        0\n",
       "3           1.5          0.2        0\n",
       "4           1.4          0.2        0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "df = pd.read_csv(\"data/iris.csv\").drop([\"sepal_width\", \"sepal_length\"], 1) # data from https://www.kaggle.com/arshid/iris-flower-dataset\n",
    "\n",
    "label_mappings = {label_str:i for i,label_str in enumerate(df[\"species\"].unique())}\n",
    "df.replace({\"species\":label_mappings}, inplace=True)\n",
    "\n",
    "permutation = np.random.permutation(df.index)\n",
    "X = np.array(df.drop([\"species\"], 1))[permutation]\n",
    "y = np.array(df[\"species\"])[permutation]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " if feature 0 is greater or equal to 3.0:\n",
      "\t if feature 1 is greater or equal to 1.8:\n",
      "\t\t if feature 0 is greater or equal to 4.9:\n",
      "\t\t\t Sample is of class 2\n",
      "\t\t else:\n",
      "\t\t\t Sample is of class 2\n",
      "\t else:\n",
      "\t\t if feature 0 is greater or equal to 5.0:\n",
      "\t\t\t if feature 1 is greater or equal to 1.6:\n",
      "\t\t\t\t if feature 0 is greater or equal to 5.8:\n",
      "\t\t\t\t\t Sample is of class 2\n",
      "\t\t\t\t else:\n",
      "\t\t\t\t\t Sample is of class 1\n",
      "\t\t\t else:\n",
      "\t\t\t\t Sample is of class 2\n",
      "\t\t else:\n",
      "\t\t\t if feature 1 is greater or equal to 1.7:\n",
      "\t\t\t\t Sample is of class 2\n",
      "\t\t\t else:\n",
      "\t\t\t\t Sample is of class 1\n",
      " else:\n",
      "\t Sample is of class 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distributions is a list where each element represents the amount of Samples belonging to each classe\n",
    "# example [20, 30] -> 20 x Sample belonging to class 0 - 30 x Sample belonging to class 1\n",
    "def gini(distributions): \n",
    "    if sum(distributions) == 0: # if there are no samples for the node\n",
    "        return 0\n",
    "    num_samples = sum(distributions)\n",
    "    impurity = 1\n",
    "    for i in distributions:\n",
    "        impurity -= (i/num_samples)**2\n",
    "    return impurity\n",
    " \n",
    "\n",
    "# decision function of the node\n",
    "def ask(descision_value, ask_value):\n",
    "    if isinstance(ask_value, int) or isinstance(ask_value, float):    \n",
    "        return ask_value >= descision_value\n",
    "    else:\n",
    "        return ask_value == descision_value\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "# end of branch\n",
    "class TreeNodeEnd():\n",
    "    def __init__(self, labels, distribution, depth):\n",
    "        self.label = int(np.bincount(labels).argmax()) # most frequent label in labels\n",
    "        self.distribution = distribution\n",
    "        self.depth = depth\n",
    "        self.gini_score = gini(self.distribution)\n",
    "        \n",
    "    def predict(self, value):\n",
    "        return self.label\n",
    "    \n",
    "    def print_tree(self):\n",
    "        print(\"\\t\"*self.depth, \"Sample is of class {}\".format(self.label))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# decision node\n",
    "class TreeNode():\n",
    "    def __init__(self, data, labels, distrb, gini, descision_value, feature, depth):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.distribution = distrb\n",
    "        self.gini_score = gini\n",
    "        self.feature = feature\n",
    "        self.descision_value = descision_value\n",
    "        self.depth = depth\n",
    "        self.child = {True:None, False:None}\n",
    "    \n",
    "    \n",
    "    def predict(self, value):            \n",
    "        return self.child[ask(self.descision_value, value[self.feature])].predict(value)\n",
    "        \n",
    "    \n",
    "    def print_tree(self):\n",
    "        cond = \"is greater or equal to\" if isinstance(self.descision_value, int) or isinstance(self.descision_value, float) else \"is equal to\" \n",
    "        print(\"\\t\"*self.depth, \"if feature {} {} {}:\".format(self.feature, cond, self.descision_value))\n",
    "        self.child[True].print_tree()\n",
    "        print(\"\\t\"*self.depth, \"else:\")\n",
    "        self.child[False].print_tree()\n",
    "   \n",
    "\n",
    "        \n",
    "    \n",
    "        \n",
    "class DescisionTreeClassifier:\n",
    "    def __init__(self, max_depth = None):\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    \n",
    "    # find the value that produces the lowest gini score and partition the data according to it\n",
    "    def find_lowest_gini(self, data, labels):\n",
    "        unique_column_values = {i:list(np.unique(column)) for i,column in enumerate(data.T) } # get only unique feature values\n",
    "        gini_score = 1\n",
    "        \n",
    "        for column in unique_column_values:\n",
    "            for unique_value in unique_column_values[column]:\n",
    "                # split data into two groups: True and False\n",
    "                split_data = {True:[], False:[]}\n",
    "                split_labels = {True:[], False:[]}\n",
    "                distrb = {True:[0] * self.class_count, False:[0] * self.class_count}\n",
    "                for i in range(len(data)):\n",
    "                    branch = ask(unique_value, data.T[column][i])\n",
    "                    split_data[branch].append(data[i])\n",
    "                    split_labels[branch].append(labels[i])\n",
    "                    distrb[branch][labels[i]] += 1\n",
    "                \n",
    "                # gini score is the weighted sum of both branches\n",
    "                new_gini = (sum(distrb[True]) / len(data) * gini(distrb[True])) + (sum(distrb[False]) / len(data) * gini(distrb[False]))\n",
    "                \n",
    "                split_data = {x:np.array(split_data[x]) for x in split_data}\n",
    "                split_labels = {x:np.array(split_labels[x]) for x in split_labels}\n",
    "                \n",
    "                if new_gini < gini_score:\n",
    "                    gini_score = new_gini\n",
    "                    lowest_gini_data = split_data, split_labels, distrb, gini_score, unique_value, column\n",
    "       \n",
    "        return lowest_gini_data\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    # recursive function, builds the tree\n",
    "    def createNextNode(self, data, labels, distribution, depth=0):\n",
    "        label = int(np.bincount(labels).argmax()) # most often occouring label\n",
    "        \n",
    "        # partition data\n",
    "        split_data, split_labels, distrb, gini_score, descision_value, feature = self.find_lowest_gini(data, labels)\n",
    "        \n",
    "        # data has to splitable\n",
    "        if list(distrb[True]) != distribution and list(distrb[False]) != distribution:\n",
    "            node = TreeNode(data, labels, distribution, gini_score, descision_value, feature, depth)\n",
    "            \n",
    "            for branch in [True, False]:\n",
    "                depth_reached = False if self.max_depth is None else True if depth+1 == self.max_depth else False\n",
    "                node_pure = distrb[branch].count(0) >= self.class_count-1\n",
    "                if depth_reached or node_pure:\n",
    "                    node.child[branch] = TreeNodeEnd(split_labels[branch], distrb[False], depth+1)\n",
    "                else:\n",
    "                    node.child[branch] = self.createNextNode(split_data[branch], split_labels[branch], distrb[branch], depth+1)\n",
    "            \n",
    "        else:\n",
    "            node = TreeNodeEnd(labels, distribution, depth)\n",
    "        return node\n",
    "        \n",
    "    \n",
    "    def fit(self, data, labels):\n",
    "        self.class_count = len(np.unique(labels))\n",
    "        distribution = [0] * len(np.unique(labels))\n",
    "        for i in range(len(labels)):\n",
    "            distribution[labels[i]] += 1\n",
    "        self.root = self.createNextNode(data, labels, distribution)\n",
    "        \n",
    "    def predict(self, sample):\n",
    "        # recoursive function, predicts class of sample\n",
    "        return self.root.predict(sample)\n",
    "    \n",
    "    def print_tree(self):\n",
    "        # recoursive function, prints decision questions of the tree\n",
    "        self.root.print_tree()\n",
    "    \n",
    "    \n",
    "    \n",
    "clf = DescisionTreeClassifier(max_depth=None)\n",
    "clf.fit(X, y)\n",
    "clf.print_tree()\n",
    "clf.predict([1,2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

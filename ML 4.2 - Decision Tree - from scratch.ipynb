{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internet Resources:\n",
    "\n",
    "[handson-ml/06_decision_trees.ipynb](https://github.com/ageron/handson-ml/blob/master/06_decision_trees.ipynb)  \n",
    "[Sefik Ilkin Serengil - A Step by Step CART Decision Tree Example](https://sefiks.com/2018/08/27/a-step-by-step-cart-decision-tree-example/)  \n",
    "[Google Developers - Tree Classifier from Scratch](https://www.youtube.com/watch?v=LDRbO9a6XPU&t=1s)  \n",
    "[Victor Zhou - A Simple Explanation of Gini Impurity](https://victorzhou.com/blog/gini-impurity/)\n",
    "\n",
    "\n",
    "Literature:  \n",
    "\n",
    "Aurelien geron hands on machine learning page 173"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   petal_length  petal_width  species\n",
       "0           1.4          0.2        0\n",
       "1           1.4          0.2        0\n",
       "2           1.3          0.2        0\n",
       "3           1.5          0.2        0\n",
       "4           1.4          0.2        0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "df = pd.read_csv(\"data/iris.csv\").drop([\"sepal_width\", \"sepal_length\"], 1)\n",
    "\n",
    "label_mappings = {label_str:i for i,label_str in enumerate(df[\"species\"].unique())}\n",
    "df.replace({\"species\":label_mappings}, inplace=True)\n",
    "\n",
    "permutation = np.random.permutation(df.index)\n",
    "X = np.array(df.drop([\"species\"], 1))[permutation]\n",
    "y = np.array(df[\"species\"])[permutation]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " if feature 0 is greater or equal to 3.0:\n",
      "\t if feature 1 is greater or equal to 1.8:\n",
      "\t\t Sample is of class 2\n",
      "\t else:\n",
      "\t\t Sample is of class 1\n",
      " else:\n",
      "\t Sample is of class 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only has the gini function\n",
    "class Node_Base:\n",
    "    # distributions is a list where each element represents the amount of Samples belonging to each classe\n",
    "    # example [20, 30] -> 20 x Sample belonging to class 0 - 30 x Sample belonging to class 1\n",
    "    def gini(self, distributions): \n",
    "        if sum(distributions) == 0: # if there are no samples for the node\n",
    "            return 0\n",
    "        num_samples = sum(distributions)\n",
    "        impurity = 1\n",
    "        for i in distributions:\n",
    "            impurity -= (i/num_samples)**2\n",
    "        return impurity\n",
    "\n",
    "    \n",
    "# end of branch\n",
    "class TreeNodeEnd(Node_Base):\n",
    "    def __init__(self, labels, distribution, depth):\n",
    "        self.label = int(np.bincount(labels).argmax()) # most frequent label in labels\n",
    "        self.distribution = distribution\n",
    "        self.depth = depth\n",
    "        self.gini_score = self.gini(self.distribution)\n",
    "        \n",
    "    def predict(self, value):\n",
    "        return self.label\n",
    "    \n",
    "    def print_tree(self):\n",
    "        print(\"\\t\"*self.depth, \"Sample is of class {}\".format(self.label))\n",
    "    \n",
    "    \n",
    "# decision node\n",
    "class TreeNode(Node_Base):\n",
    "    # decision function of the node\n",
    "    def ask(self, question_value, ask_value):\n",
    "        if isinstance(ask_value, int) or isinstance(ask_value, float):    \n",
    "            return ask_value >= question_value\n",
    "        else:\n",
    "            return ask_value == question_value\n",
    "        \n",
    "    def partition(self, qValue, column, data, labels, unique_label_count):\n",
    "        # split data into two groups: True and False\n",
    "        split_data = {True:[], False:[]}\n",
    "        split_labels = {True:[], False:[]}\n",
    "        distrb = {True:[0] * unique_label_count, False:[0] * unique_label_count}\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            branch = self.ask(qValue, data.T[column][i])\n",
    "            split_data[branch].append(data[i])\n",
    "            split_labels[branch].append(labels[i])\n",
    "            distrb[branch][labels[i]] += 1\n",
    "        \n",
    "        # gini score is the weighted sum of both branches\n",
    "        gini_score = (sum(distrb[True]) / len(data) * self.gini(distrb[True])) + (sum(distrb[False]) / len(data) * self.gini(distrb[False]))\n",
    "        \n",
    "        split_data = {x:np.array(split_data[x]) for x in split_data}\n",
    "        split_labels = {x:np.array(split_labels[x]) for x in split_labels}\n",
    "        return split_data, split_labels, distrb, gini_score\n",
    "    \n",
    "    \n",
    "    def __init__(self, data, labels, unique_label_count, max_depth, depth=0):\n",
    "        self.label = int(np.bincount(labels).argmax()) # most often occouring label\n",
    "        self.gini_score = -1\n",
    "        self.depth = depth\n",
    "       \n",
    "        unique_column_values = {i:list(np.unique(column)) for i,column in enumerate(data.T) } # get only unique feature values\n",
    "        \n",
    "        self.gini_score = 1\n",
    "        # iterate through every feature value and find the one that produces the lowest gini score\n",
    "        for column in unique_column_values:\n",
    "            for unique_value in unique_column_values[column]:\n",
    "                # split data into two groups: True and False by running every Sample through the descision function of the node (self.ask)\n",
    "                # in self.partition unique_value is passed to self.ask as parameter question_value\n",
    "                split_data, split_labels, distrb, gini_score = self.partition(unique_value, column, data, labels, unique_label_count)\n",
    "                # the unqiue_value that produces the lowest gini score is stored as self.question_value\n",
    "                if gini_score < self.gini_score:\n",
    "                    self.gini_score = gini_score\n",
    "                    self.split_data = split_data\n",
    "                    self.split_labels = split_labels\n",
    "                    self.distribution = distrb\n",
    "                    self.question_value = unique_value\n",
    "                    self.feature = column\n",
    "        \n",
    "        # recursive binary splitting\n",
    "        self.child = {True:None, False:None}\n",
    "        for branch in [True, False]:\n",
    "            # if either the maximum depth (=number of nodes in a branch) is reached or the training samples for the next node are all of the same class\n",
    "            if depth+1==max_depth or self.distribution[branch].count(0) >= unique_label_count-1:\n",
    "                self.child[branch] = TreeNodeEnd(self.split_labels[branch], self.distribution[branch], depth+1) # end of recursion\n",
    "            else:\n",
    "                self.child[branch] = TreeNode(self.split_data[branch], self.split_labels[branch], unique_label_count, max_depth, depth+1)\n",
    "        \n",
    "        \n",
    "    def predict(self, value):\n",
    "        return self.child[self.ask(self.question_value, value[self.feature])].predict(value)\n",
    "    \n",
    "    \n",
    "    def print_tree(self):\n",
    "        cond = \"is greater or equal to\" if isinstance(self.question_value, int) or isinstance(self.question_value, float) else \"is equal to\" \n",
    "        print(\"\\t\"*self.depth, \"if feature {} {} {}:\".format(self.feature, cond, self.question_value))\n",
    "        self.child[True].print_tree()\n",
    "        print(\"\\t\"*self.depth, \"else:\")\n",
    "        self.child[False].print_tree()\n",
    "        \n",
    "        \n",
    "        \n",
    "class DescisionTreeClassifier:\n",
    "    def __init__(self, max_depth):\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def fit(self, data, labels):\n",
    "        # recursive function, builds the tree\n",
    "        unique_column_values = {i:list(np.unique(column)) for i,column in enumerate(data.T) } # .T = Transpose\n",
    "        unique_label_count = len(np.unique(labels))\n",
    "        self.root = TreeNode(data, labels, unique_label_count, self.max_depth)\n",
    "       \n",
    "    def predict(self, sample):\n",
    "        # recoursive function, predicts class of sample\n",
    "        return self.root.predict(sample)\n",
    "    \n",
    "    def print_tree(self):\n",
    "        # recoursive function, prints decision questions of the tree\n",
    "        self.root.print_tree()\n",
    "    \n",
    "    \n",
    "    \n",
    "clf = DescisionTreeClassifier(max_depth=2)\n",
    "clf.fit(X, y)\n",
    "clf.print_tree()\n",
    "clf.predict([3,2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
